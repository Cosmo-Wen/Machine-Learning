{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":150,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":151,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv'  # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv'       # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  []                    # Initial datalist, saved as numpy array\n","output_datalist =  []                   # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","                                        # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":152,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["# Dataset and datacount\n","training_data = []\n","validation_data = []\n","prediction_data = []\n","training_data_count = 84\n","test_data_count = 10\n","\n","# Cleaning parameters\n","upper_percent = 90\n","lower_percent = 10\n","\n","# Regression Parameters\n","autoregression = 0\n","max_degree = 2"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":153,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","    input_datalist = np.array(list(csv.reader(csvfile)))\n","input_datalist = input_datalist[1: ]"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":154,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["def SplitData():\n","    global training_data, validation_data, prediction_data\n","    \n","    # Reset datalists\n","    training_data = []\n","    validation_data = []\n","    prediction_data = []\n","    \n","    # Assign training data\n","    for data in input_datalist[0: training_data_count]:\n","        entry = [int(data[0])]\n","        for cell in data[1: ]:\n","            if cell == \"\":\n","                cell = 0\n","            entry.append(float(cell))\n","        training_data.append(entry)\n","\n","    # Assign validation data\n","    for data in input_datalist[training_data_count: training_data_count + test_data_count]:\n","        entry = [int(data[0])]\n","        for cell in data[1: ]:\n","            if cell == \"\":\n","                cell = 0\n","            entry.append(float(cell))\n","        validation_data.append(entry)\n","    \n","    # Assign prediction data\n","    for data in input_datalist[training_data_count + test_data_count: training_data_count + 2 * test_data_count]:\n","        entry = [int(data[0])]\n","        for cell in data[1: ]:\n","            if cell == \"\":\n","                cell = 0\n","            entry.append(float(cell))\n","        prediction_data.append(entry)\n","\n","    # Transpose data\n","    training_data = np.transpose(np.asarray(training_data, dtype = object))\n","    validation_data = np.transpose(np.asarray(validation_data, dtype = object))\n","    prediction_data = np.transpose(np.asarray(prediction_data, dtype = object))\n","SplitData()"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":155,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["from numpy import percentile\n","\n","\n","def PreprocessData():\n","    global training_data\n","\n","    # Clean data with IQR substitution\n","    for i in range(1, len(training_data)):\n","        # percentile_lower = np.percentile(training_data[i], lower_percent)\n","        # percentile_upper = np.percentile(training_data[i], upper_percent)\n","        Q1 = np.percentile(training_data[i], 25)\n","        Q3 = np.percentile(training_data[i], 75)\n","        IQR = Q3 - Q1\n","        percentile_lower = Q1 - 1.5 * IQR\n","        percentile_upper = Q3 + 1.5 * IQR\n","        for j in range(0, len(training_data[i])):\n","            if training_data[i][j] < percentile_lower:\n","                training_data[i][j] = percentile_lower\n","            elif training_data[i][j] >= percentile_upper:\n","                training_data[i][j] = percentile_upper\n","PreprocessData()"]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":156,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["def Regression(temp, case):\n","    global autoregression, max_degree\n","\n","    M = []\n","    # Matrix Inversion\n","    if autoregression != 0:\n","        for i in range(autoregression, len(temp)):\n","            phi = [1, temp[i]]\n","            for j in range(1, autoregression + 1):\n","                phi.append(case[i - j])             # phi = 1 + temp[i] + case[i - 1] + ...\n","            M.append(phi)\n","        coef = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(M), M)), np.transpose(M)), case[autoregression: ])\n","    else:\n","        for cell in temp:\n","            phi = []\n","            for i in range(0, max_degree + 1):\n","                phi.append(cell ** i)               # phi = 1 + temp[i] + temp^2[i] + ...\n","            M.append(phi)\n","        # w = (phi^T * phi)^-1 * y\n","        coef = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(M), M)), np.transpose(M)), case)\n","    return coef\n","coef = Regression(training_data[1], training_data[4])"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":157,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[],"source":["def MakePrediction(coef, temp, case):\n","    global autoregression, max_degree\n","\n","    result = []\n","    for i in range(0, len(temp)):\n","        if autoregression != 0:\n","            predict = coef[0] + coef[1] * temp[i] \n","            ### i dont start from 0 but start from the frist entry that can be autoregressed, and change case[i - j] to resul[i - j] \n","            for j in range(1, autoregression + 1):\n","                predict += coef[j + i] * case[i - j]\n","        else:\n","            predict = 0\n","            for j in range(0, max_degree + 1):\n","                predict += coef[j] * (temp[i] ** j)\n","        result.append(predict)\n","    return result[autoregression: ]"]},{"cell_type":"markdown","metadata":{},"source":["### Step 4.1: Utility Functions\n","Utility functions for visualizations and monitoring errors"]},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[],"source":["def MAPE(coef, id):\n","    global autoregression\n","\n","    temp = []\n","    case = []\n","    if autoregression != 0:\n","        for i in range(1, autoregression + 1):\n","            temp.append(training_data[id][len(training_data[id]) - i])\n","        for entry in validation_data[id]:\n","            temp.append(entry)\n","        case.append(training_data[id + 3][len(training_data[id + 3]) - i])\n","        for entry in validation_data[id + 3]:\n","            case.append(entry)\n","    else:\n","        temp = validation_data[id]\n","        case = validation_data[id + 3]\n","    predict = MakePrediction(coef, temp, case)\n","    error = 0\n","\n","    for i in range(0, len(predict)):\n","        error = error + abs((validation_data[i] - predict[i]) / case[i])\n","    return error / len(case[0]) * 100"]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    for row in output_datalist:\n","        writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"4e04567cf9f7b3102900e1f6f80f1b4ef7679b70ac39797045d335daa36856c7"}}},"nbformat":4,"nbformat_minor":0}
